{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69aa55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Google Colabで実行することを前提としている(無料でGPUを使うため)\n",
    "# そのとき以下の操作を行う\n",
    "# 1. その他の接続オプションを押下\n",
    "# 2. ランタイムのタイプを変更を押下\n",
    "# 3. T4 GPUのラジオボタンにチェックを入れる\n",
    "# 4. 保存ボタンを押下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcfcd1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate sentencepiece fugashi unidic-lite\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015ce69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    \"\"\"アヤメ分類チャットボット用の学習データを作成\"\"\"\n",
    "    \n",
    "    training_data = [\n",
    "        # 基本的な挨拶\n",
    "        {\"instruction\": \"こんにちは\", \"output\": \"こんにちは！アヤメ分類システムのアシスタントです。アヤメの品種判定や測定値について、何でもお聞きください。\"},\n",
    "        {\"instruction\": \"はじめまして\", \"output\": \"はじめまして！アヤメの花の分類をお手伝いするAIアシスタントです。どうぞよろしくお願いします。\"},\n",
    "        {\"instruction\": \"何ができますか？\", \"output\": \"私は、アヤメの花の測定値（がく片の長さ・幅、花弁の長さ・幅）から、3つの品種（Setosa、Versicolor、Virginica）を判定するお手伝いができます。\"},\n",
    "        {\"instruction\": \"使い方を教えて\", \"output\": \"4つの測定値を入力してください：1. がく片の長さ（cm）、2. がく片の幅（cm）、3. 花弁の長さ（cm）、4. 花弁の幅（cm）。これらの値から品種を予測します。\"},\n",
    "        {\"instruction\": \"どうやって使うの？\", \"output\": \"アヤメの花を測定して、がく片と花弁のサイズ（長さと幅）を入力してください。センチメートル単位で入力すると、品種を判定します。\"},\n",
    "        \n",
    "        # アヤメについての基本情報\n",
    "        {\"instruction\": \"アヤメとは\", \"output\": \"アヤメ（Iris）は、アヤメ科アヤメ属の美しい花を咲かせる多年草です。世界中に約300種が分布し、日本でも古くから親しまれています。\"},\n",
    "        {\"instruction\": \"アヤメの分類について教えてください\", \"output\": \"アヤメの分類は、Fisher's Iris datasetとして有名で、機械学習の入門的な教材です。花の4つの測定値から3つの品種を識別します。\"},\n",
    "        {\"instruction\": \"アイリスデータセットとは\", \"output\": \"1936年にロナルド・フィッシャーが発表した、統計学と機械学習で最も有名なデータセットの一つです。150個のアヤメのサンプルが含まれています。\"},\n",
    "        {\"instruction\": \"Irisとは何ですか\", \"output\": \"Irisはアヤメの英語名です。ギリシャ神話の虹の女神イリスに由来し、虹のように多彩な花の色を持つことから名付けられました。\"},\n",
    "        \n",
    "        # 入力についての詳細\n",
    "        {\"instruction\": \"入力は何か？\", \"output\": \"4つの測定値を入力します：がく片の長さ（Sepal Length）、がく片の幅（Sepal Width）、花弁の長さ（Petal Length）、花弁の幅（Petal Width）です。\"},\n",
    "        {\"instruction\": \"どんな値を入力すればいい？\", \"output\": \"一般的な範囲は、がく片の長さ：4-8cm、がく片の幅：2-5cm、花弁の長さ：1-7cm、花弁の幅：0.1-3cmです。\"},\n",
    "        {\"instruction\": \"単位は何？\", \"output\": \"すべての測定値の単位はセンチメートル（cm）です。ミリメートルではないので注意してください。\"},\n",
    "        {\"instruction\": \"単位は何ですか\", \"output\": \"測定値はすべてセンチメートル（cm）単位で入力してください。小数点以下の値も入力可能です。\"},\n",
    "        {\"instruction\": \"測定方法は？\", \"output\": \"定規やノギスを使って、花の各部分を正確に測定してください。がく片は外側の大きな花弁、花弁は内側の小さな花弁です。\"},\n",
    "        {\"instruction\": \"どうやって測るの？\", \"output\": \"完全に開花した花を選び、定規で各部分の最大値を測定します。がく片は外側、花弁は内側の部分です。\"},\n",
    "        \n",
    "        # 品種についての詳細情報\n",
    "        {\"instruction\": \"Setosaとは\", \"output\": \"Iris Setosa（ヒオウギアヤメ）は、最も小型の品種で、花弁が短く、がく片も比較的小さいのが特徴です。北米やアジアに分布しています。\"},\n",
    "        {\"instruction\": \"セトサとは\", \"output\": \"セトサ（Setosa）は3つのアヤメ品種の中で最も小さく、花弁の長さが1-2cm程度です。他の品種と明確に区別できます。\"},\n",
    "        {\"instruction\": \"Versicolorとは\", \"output\": \"Iris Versicolor（ブルーフラッグ）は、中型の品種で、青紫色の美しい花を咲かせます。北アメリカ東部原産です。\"},\n",
    "        {\"instruction\": \"バーシカラーとは\", \"output\": \"バーシカラー（Versicolor）は中間サイズのアヤメで、花弁の長さが3-5cm程度です。青や紫の美しい花を咲かせます。\"},\n",
    "        {\"instruction\": \"Virginicaとは\", \"output\": \"Iris Virginica（バージニアアヤメ）は、最も大型の品種で、大きな花弁と長いがく片が特徴です。北アメリカ原産です。\"},\n",
    "        {\"instruction\": \"バージニカとは\", \"output\": \"バージニカ（Virginica）は3品種の中で最大のアヤメで、花弁の長さが5-7cmに達します。堂々とした大輪の花を咲かせます。\"},\n",
    "        {\"instruction\": \"品種の違いは？\", \"output\": \"Setosaは最も小型、Virginicaは最も大型、Versicolorは中間サイズです。特に花弁の長さで明確に区別できます。\"},\n",
    "        {\"instruction\": \"どの品種が一番大きい？\", \"output\": \"Virginicaが最も大きく、花弁の長さは5-7cm、がく片の長さは6-8cmに達します。\"},\n",
    "        {\"instruction\": \"一番小さい品種は？\", \"output\": \"Setosaが最も小さく、花弁の長さは1-2cm程度で、他の品種と比べて明らかに小型です。\"},\n",
    "        {\"instruction\": \"3つの品種の特徴は？\", \"output\": \"Setosa：小型で花弁が短い、Versicolor：中型で青紫の花、Virginica：大型で堂々とした花。主に花弁の長さで区別できます。\"},\n",
    "        \n",
    "        # 予測と精度について\n",
    "        {\"instruction\": \"確率は何を表している？\", \"output\": \"確率は、入力された測定値が各品種（Setosa、Versicolor、Virginica）に属する可能性を0-100%で表します。最も高い確率の品種が予測結果です。\"},\n",
    "        {\"instruction\": \"確率とは\", \"output\": \"各品種である可能性をパーセンテージで表示します。例えば「Setosa: 95%」なら、95%の確信度でSetosaと判定されたことを意味します。\"},\n",
    "        {\"instruction\": \"精度はどのくらい？\", \"output\": \"通常、このモデルの精度は95%以上です。ただし、品種の境界付近の個体では確率が下がることがあります。\"},\n",
    "        {\"instruction\": \"予測が間違うことはある？\", \"output\": \"はい、特にVersicolorとVirginicaは似た特徴を持つため、境界付近の個体では誤分類することがあります。\"},\n",
    "        {\"instruction\": \"信頼度が低い場合は？\", \"output\": \"確率が60%未満の場合は、測定値を再確認するか、複数の花で測定して平均値を使用することをお勧めします。\"},\n",
    "        {\"instruction\": \"なぜ間違うことがあるの？\", \"output\": \"自然界の花には個体差があり、品種の境界付近では特徴が重なることがあるためです。特にVersicolorとVirginicaは似ています。\"},\n",
    "        \n",
    "        # 実用的な例\n",
    "        {\"instruction\": \"例を見せて\", \"output\": \"例：がく片の長さ5.1cm、幅3.5cm、花弁の長さ1.4cm、幅0.2cmの場合、高い確率でSetosaと判定されます。\"},\n",
    "        {\"instruction\": \"典型的なSetosaの値は？\", \"output\": \"典型的なSetosa：がく片の長さ5.0cm、幅3.4cm、花弁の長さ1.5cm、幅0.2cm前後です。\"},\n",
    "        {\"instruction\": \"典型的なVersicolorの値は？\", \"output\": \"典型的なVersicolor：がく片の長さ6.0cm、幅2.8cm、花弁の長さ4.5cm、幅1.3cm前後です。\"},\n",
    "        {\"instruction\": \"典型的なVirginicaの値は？\", \"output\": \"典型的なVirginica：がく片の長さ7.0cm、幅3.0cm、花弁の長さ6.0cm、幅2.0cm前後です。\"},\n",
    "        {\"instruction\": \"サンプルデータを教えて\", \"output\": \"Setosa: [5.1, 3.5, 1.4, 0.2]、Versicolor: [6.0, 2.7, 4.5, 1.3]、Virginica: [6.9, 3.1, 5.9, 2.1]が典型例です。\"},\n",
    "        \n",
    "        # システムについて\n",
    "        {\"instruction\": \"このシステムは何？\", \"output\": \"機械学習を使用したアヤメ品種分類システムです。花の測定値から自動的に品種を判定します。\"},\n",
    "        {\"instruction\": \"どうやって動いている？\", \"output\": \"入力された4つの測定値を機械学習モデルで分析し、過去のデータと比較して最も可能性の高い品種を予測します。\"},\n",
    "        {\"instruction\": \"機械学習とは？\", \"output\": \"コンピュータがデータからパターンを学習し、新しいデータに対して予測を行う技術です。このシステムでは150個のアヤメのデータから学習しています。\"},\n",
    "        {\"instruction\": \"AIなの？\", \"output\": \"はい、機械学習を使用したAIシステムです。過去のデータから学習し、新しい花の品種を予測できます。\"},\n",
    "        {\"instruction\": \"どれくらい賢いの？\", \"output\": \"アヤメの分類に特化しており、95%以上の精度で品種を判定できます。ただし、アヤメの分類以外はできません。\"},\n",
    "        \n",
    "        # 測定のコツと注意点\n",
    "        {\"instruction\": \"測定のコツは？\", \"output\": \"1. 完全に開花した花を選ぶ、2. 最も大きな部分を測定、3. 複数の花で測定して平均を取る、4. ミリ単位まで正確に測定することが重要です。\"},\n",
    "        {\"instruction\": \"がく片とは？\", \"output\": \"がく片（Sepal）は、花の外側にある緑色または色付きの葉のような部分です。通常3枚あり、花弁を保護する役割があります。\"},\n",
    "        {\"instruction\": \"花弁とは？\", \"output\": \"花弁（Petal）は、花の内側にある色鮮やかな部分です。アヤメでは通常3枚あり、昆虫を引き寄せる役割があります。\"},\n",
    "        {\"instruction\": \"がく片と花弁の違いは？\", \"output\": \"がく片は花の外側の大きな部分で、通常緑色です。花弁は内側の色鮮やかな部分で、より小さく繊細です。\"},\n",
    "        {\"instruction\": \"正確に測るには？\", \"output\": \"デジタルノギスを使用すると0.1mm単位で正確に測定できます。また、3つ以上の花を測定して平均値を使うとより正確です。\"},\n",
    "        \n",
    "        # エラー対応\n",
    "        {\"instruction\": \"エラーが出た\", \"output\": \"申し訳ございません。入力値が正しい範囲内か確認してください。すべて正の数値（cm単位）である必要があります。\"},\n",
    "        {\"instruction\": \"動かない\", \"output\": \"入力欄に4つの数値（がく片の長さ、幅、花弁の長さ、幅）をすべて入力してから予測ボタンを押してください。\"},\n",
    "        {\"instruction\": \"結果が出ない\", \"output\": \"しばらくお待ちください。それでも表示されない場合は、ページを更新してもう一度お試しください。\"},\n",
    "        {\"instruction\": \"入力できない\", \"output\": \"数値のみ入力可能です。単位（cm）は自動的に付加されるので、数字だけを入力してください。\"},\n",
    "        {\"instruction\": \"おかしな結果が出る\", \"output\": \"入力値の単位を確認してください。センチメートル（cm）で入力する必要があります。ミリメートルで入力していませんか？\"},\n",
    "        \n",
    "        # 雑談・その他\n",
    "        {\"instruction\": \"ありがとう\", \"output\": \"どういたしまして！アヤメの分類について、他にも質問があればお気軽にどうぞ。\"},\n",
    "        {\"instruction\": \"さようなら\", \"output\": \"ご利用ありがとうございました。またアヤメの分類でお困りの際はお声がけください！\"},\n",
    "        {\"instruction\": \"すごい\", \"output\": \"ありがとうございます！機械学習の力で、アヤメの品種を高精度で判定できるんです。\"},\n",
    "        {\"instruction\": \"間違っている\", \"output\": \"申し訳ございません。測定値を再確認いただくか、別の花で試してみてください。境界付近の個体は判定が難しいことがあります。\"},\n",
    "        {\"instruction\": \"もっと詳しく\", \"output\": \"何について詳しく知りたいですか？品種の特徴、測定方法、予測の仕組みなど、お答えできます。\"},\n",
    "        {\"instruction\": \"助けて\", \"output\": \"お手伝いします！アヤメの測定方法、入力の仕方、結果の見方など、どんなことでお困りですか？\"},\n",
    "        {\"instruction\": \"わからない\", \"output\": \"大丈夫です。まず、アヤメの花を用意して、4つの部分（がく片の長さと幅、花弁の長さと幅）を測定することから始めましょう。\"},\n",
    "        \n",
    "        # 追加の専門的な質問\n",
    "        {\"instruction\": \"フィッシャーとは誰？\", \"output\": \"ロナルド・フィッシャーは20世紀の偉大な統計学者で、1936年にアヤメのデータセットを使った判別分析を発表しました。\"},\n",
    "        {\"instruction\": \"なぜアヤメなの？\", \"output\": \"アヤメは品種ごとに測定可能な明確な特徴があり、データ収集が容易で、機械学習の教材として理想的だからです。\"},\n",
    "        {\"instruction\": \"他の花でもできる？\", \"output\": \"もちろん可能ですが、このシステムはアヤメ専用です。他の花には別のモデルが必要になります。\"},\n",
    "        {\"instruction\": \"日本のアヤメとは違う？\", \"output\": \"このシステムで扱うのは西洋アヤメ（Iris）で、日本の伝統的なアヤメとは異なる種類です。\"},\n",
    "        {\"instruction\": \"いつ頃のデータ？\", \"output\": \"元のデータは1936年に収集されたもので、現在も機械学習の標準的なデータセットとして使われています。\"},\n",
    "    ]\n",
    "    \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1e365",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(training_data, tokenizer):\n",
    "    \"\"\"データセットの準備\"\"\"\n",
    "    \n",
    "    # プロンプト形式でデータを整形\n",
    "    formatted_data = []\n",
    "    for item in training_data:\n",
    "        # 学習用のプロンプト形式\n",
    "        text = f\"### 質問: {item['instruction']}\\n### 回答: {item['output']}{tokenizer.eos_token}\"\n",
    "        formatted_data.append({'text': text})\n",
    "    \n",
    "    # Dataset作成\n",
    "    dataset = Dataset.from_list(formatted_data)\n",
    "    \n",
    "    # トークナイズ関数\n",
    "    def tokenize_function(examples):\n",
    "        outputs = tokenizer(\n",
    "            examples['text'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=256\n",
    "        )\n",
    "        outputs['labels'] = outputs['input_ids'].copy()\n",
    "        return outputs\n",
    "    \n",
    "    # トークナイズ実行\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac5d7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"日本語アヤメ分類チャットボットの学習開始\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 学習データの作成\n",
    "print(\"\\n📝 学習データを作成中...\")\n",
    "training_data = create_training_data()\n",
    "print(f\"   ✅ {len(training_data)}件の学習データを作成しました\")\n",
    "\n",
    "# training_data.jsonlとして保存（ルールベース用）\n",
    "with open('training_data.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "print(\"   💾 training_data.jsonlに保存しました\")\n",
    "\n",
    "# モデルとトークナイザーの準備（GPT-2を使用）\n",
    "print(\"\\n🤖 モデルを準備中...\")\n",
    "# 日本語モデルは学習が難しいので、標準のGPT-2を使用\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "print(f\"   ✅ {model_name}を読み込みました\")\n",
    "\n",
    "# パディングトークンの設定\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "print(\"   ⚙️ トークナイザーの設定完了\")\n",
    "\n",
    "# データセットの準備（改善版）\n",
    "print(\"\\n📊 データセットを準備中...\")\n",
    "\n",
    "# より簡潔なプロンプト形式\n",
    "formatted_data = []\n",
    "for item in training_data:\n",
    "    # 英語と日本語の混在を避けるため、シンプルな形式\n",
    "    text = f\"Q: {item['instruction']}\\nA: {item['output']}<|endoftext|>\"\n",
    "    formatted_data.append({'text': text})\n",
    "\n",
    "dataset = Dataset.from_list(formatted_data)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    outputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128  # 短くして学習を安定化\n",
    "    )\n",
    "    outputs['labels'] = outputs['input_ids'].copy()\n",
    "    return outputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "print(f\"   ✅ {len(tokenized_dataset)}件のデータをトークナイズしました\")\n",
    "\n",
    "# 学習の設定（調整版）\n",
    "print(\"\\n⚙️ 学習設定を構成中...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./iris_model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=20,  # エポック数を増やす\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=3e-5,  # 学習率を下げる\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "# データコレーターの設定\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# トレーナーの初期化\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 学習の実行\n",
    "print(\"\\n🚀 学習を開始します...\")\n",
    "print(\"   ⏱️ これには10-15分程度かかる場合があります...\")\n",
    "trainer.train()\n",
    "print(\"   ✅ 学習完了！\")\n",
    "\n",
    "# モデルの保存\n",
    "print(\"\\n💾 モデルを保存中...\")\n",
    "trainer.save_model(\"./iris_model\")\n",
    "tokenizer.save_pretrained(\"./iris_model\")\n",
    "\n",
    "# config.jsonにモデルタイプを明示的に保存\n",
    "import json\n",
    "config_path = \"./iris_model/config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "config['model_type'] = 'gpt2'\n",
    "config['task'] = 'iris_classification_chat'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"   ✅ ./iris_modelに保存しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc7a66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n🧪 モデルのテスト...\")\n",
    "test_prompts = [\n",
    "    \"アヤメとは\",\n",
    "    \"Setosaとは\",\n",
    "    \"使い方を教えて\",\n",
    "    \"典型的なVersicolorの値は？\",\n",
    "    \"ありがとう\"\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "for prompt in test_prompts:\n",
    "    full_prompt = f\"### 質問: {prompt}\\n### 回答:\"\n",
    "    inputs = tokenizer.encode(full_prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # GPUが使用可能な場合は使用\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        model = model.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs, \n",
    "            max_length=150,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.8,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response.replace(full_prompt, \"\").strip()\n",
    "    \n",
    "    # 最初の文だけを表示（長すぎる場合）\n",
    "    if len(response) > 100:\n",
    "        response = response[:100] + \"...\"\n",
    "    \n",
    "    print(f\"\\n   Q: {prompt}\")\n",
    "    print(f\"   A: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3bf4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!zip -r iris_model.zip iris_model/\n",
    "print(\"   ✅ iris_model.zipを作成しました\")\n",
    "\n",
    "print(\"\\n📥 ダウンロードの準備...\")\n",
    "from google.colab import files\n",
    "files.download('iris_model.zip')\n",
    "print(\"   ✅ ダウンロードを開始します\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎉 完了！\")\n",
    "print(\"iris_model.zipがダウンロードされました。\")\n",
    "print(\"このファイルを解凍して、Dockerコンテナの\")\n",
    "print(\"./llm/ディレクトリに配置してください。\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
